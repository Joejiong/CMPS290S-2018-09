This paper presents Naiad, which allows for iterative processing on a data stream, interactive queries, and with low latency.  Apparently as of 2013 this was not available with other general purpose programming models. The authors present a programming model they call “timely dataflow” which is intended to allow for dataflow feedback, stateful dataflow vertices (for some reason this term confused the heck out of me for a good 10 minutes), and some way for the vertices to report when they have finished an iteration of computation which allows for outputing the results of intermediate stages. Timely dataflow is intended as a lower level building block upon which libraries and domain specific languages can then be built. As a result this paper goes into more detail about implementation and design issues like lock contention, packet loss, garbage collection, etc. Which appears to be more rare for the papers we have covered in this class. Timely dataflow is represented as a graph of stateful vertices that will send and receive messages along the graph’s edges. The authors present their own model for a logical clock that includes an epoch number and the loop counters.  With each counter being a different nested loop in the graph. Messages and notification requests are called events and are designated by pointstamps, a combination of a location in the graph and a timestamp. The Naiad runtime is implemented as a group of processes that contain workers which then manage part of the dataflow’s vertices (figure 5 is a bit confusing to look at at first, lack of labels). A Naiad program is described as a logical graph which is then expanded into a physical graph. Workers are used to deliver messages to different partitions of the graph.  A lot of section 3 in this paper reads more like a systems design document  than a programming languages paper. One interfaces with the author’s Naiad implementation through the use of a C# API. The example program given implements a basic MapReduce computation (I still don’t like wordcount as a benchmark). 


What I did not understand in this paper was the rather dense (at least to my sleep deprived mind) introduction that didn’t do a good job of defining terms. The rest of the paper was much more understandable. While I can’t quite pinpoint a single major thing I learned from this paper, moreso a lot of small details.
