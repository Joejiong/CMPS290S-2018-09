Burckhardt!

So this paper appears to be a user-friendly replicated-programming model (a specialisation
of CRDTs to only need to synchronise along fork-join pathways, it looks like), with basic
datatypes, replicated arrays, and OR-sets. `yield` and `flush` gives us replication and
synchronisation points, and `barrier` is … a synchronisation barrier?

Each base type contributes a fork-join automata to the programming model on each replica,
which we then compose together within the language. A fork-join automata checks on joins
that the data being joined is downstream of the same fork. “Round numbers” (some variation
of vector clocks?) essentially track how many forks each replica has seen.

Depending on where you are within a fork (I think), a `yield` is either allowed to noop,
must push data to its upstream, or must pull data from its downstream. `flush` then
appears to push and pull changes all the way up to the first upstream “main” server.

So. The integer data type supports modification by setting it, or
adding(/subtracting). The data tracks a base and a delta, alongside a boolean indicating
whether this replica has set that data. On a join, we know the joinee lived for shorter
than the joiner, so we can assume its data if it executed a set, and otherwise pull in its
delta. If both sides executed a join, we bias towards the joinee (most-recently-forked) replica, using the fork/join asymmetry.

The string data type support setting and conditional-set (if empty), so it tracks the
current value, whether it's been written, and whether it's been conditionally written. The
conditional write test is checked both when it's executed and on a merge.

The “complete state” essentially seems to track a hashmap of names to values, where these
names can be unique ids (“entities”) or user-readable names. Forking and joining this
datatype is just forking and joining each of its elements.

Sets just appear to be OR-sets, which neatly seems to fall out of this model via its
implementation of unique objects as “entities”.
