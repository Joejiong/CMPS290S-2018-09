## Response: 'Causal memory: definitions, implementation, and programming'

### Summary

The main motivation of the paper is to provide abstraction of shared memory in distributed computing systems. Causal memory provides an abstraction which ensures that processes in system agree on relative ordering of operations that are causally related. It is weakly consistent, so it admits more executions than either atomic or sequentially consistent memories. The paper contrasts three consistency models, namely, sequential consistency, pipelined RAM and causal consistency. In PRAM, writes done by a single process are received by all other processes in the order in which they were issued, but writes from different processes may be seen in a different order by different processes. In causal memory, writes that are potentially causally related must be seen by all processes in the same order. Concurrent writes may be seen in a different order on different machines. The paper defines two class of programs, called, concurrent-write free and data-race free which can be executed in causally consistent memory.

### What’s one thing I learned?
Causal consistency model, lamport and vector timestamps are new concepts for me.
### What’s something I didn’t understand?
It would be great if we can discuss some examples which clearly explain concurrent-write free and data-race free programs.

### What’s a research-level question I have after having read this paper?
The paper mentions that systems use causal consistent memory models in practice and programs written for sequential consistent memory models can execute well in causal consistency models. What all current systems are based on this theory?
### What’s a concrete step I can take toward answering the research question?
Enquiring further into the current systems and their implementation of underlying memory models.
