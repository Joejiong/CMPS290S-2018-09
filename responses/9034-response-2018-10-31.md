# Disciplined Inconsistency with Consistency Types

Brandon Holt, James Bornholt, Irene Zhang, Dan Ports, Mark Oskin, Luis Ceze

## Summary

The authors present abstract data types and a programming model to ensure
better performance by dynamically weakening guarantees that the system
offers about consistency. The author's present IPA : Inconsistence,
Performance-bound, Approximate model to program for better performance.

Much like the other IPAs coming out of Seattle, this offers a bitter 
solution to the problem, allowing programmers to specify regions
where consistency could compromised, or errors could be tolerated up to 
a specified extent.

Because of this design, there could be issues where weaker consistency,
hops into stronger consistency types, and to prevent this, the authors
introduce _consistency safety_, a property that guarantees that consistency
drops will not flow to stricter consistency requirements. The authors also 
introduce consistency types, which allow the type checker to ensure
consistency.

The authors introduce error bounded consistency properties, which weakens 
the consistency and uses approximation with small error margins to boost 
performance. This is encapsulated in interval types, which provide the
calculated value and the error margins LatencyBound is another option 
possible in this model, where a custom "Rushed" type delivers on latency 
guarantees. For example, if within the specified time, the operation cannot
get a quorum, it can proceed with a local quorum, weakening the consistency 
level.

The best part about the IPA model is that objects can be defined with
consistency properties, and the properties are maintained for the lifetime
of the object. The policies can be static or dynamic.
 
## Interesting Points

The error interval model is extremely similar to how most approximation
algorithms work in math libraries. It is an excellent idea that the authors
picked up on. If you can afford a small margin of error, you can save a lot
of time! It would be interesting to discuss what kind of approximations the
authors implemented.

The authors don't discuss what kind of overhead the monitor process adds. 
I further find the strict weak and strong analysis insufficient. It is 
going to be faster than strong and slightly slower than weak in situations
where guarantees are weakened. While it is useful to know that it is
comparable to weak while promising more, it would be interesting to see
how it compares to other stronger than weak guarantee systems.

## Research level question

Is the IPA model used in some modern systems? It seems like a great idea
however, I am not sure how you would converge if you dynamically kept 
changing consistency levels.

## Closing thoughts

The paper was an interesting read, and I enjoy reading about systems that
use techniques from related fields and apply them to get solutions. 
Overall the paper was strong bodied with a clean, bready, and balancing 
solution for performance.
