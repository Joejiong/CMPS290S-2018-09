This is a Brewer article? thinkpiece? from 2012, aiming to move the conversation towards a
more nuanced view of the CAP theorem. Brewer states clearly that the theorem only forbids
one point: full consistency, full availability, and full partition tolerance; with an
associated corollary that every one of these properties are graduated and
context-dependent, not global and binary.

While consistency and availability are obviously graduated, partition tolerance is as
well—the decisions boil down to how you detect and recover from partitions. Furthermore:

1. while the system is not within a partition, there's little reason to sacrifice either
        consistency or availability

2. the decision of where on the tradeoff to push can be made independently, at fine
        granularity, and without any necessity for cohesion, by various subsystems within
        the system.

Specifically, partitions are essentially graduated on latency. There will always be a
point where a node has incurred a timeout, and will have to decide whether to cancel (or
retry, incurring further latency, i.e., more graduated-partition-ness) the operation,
forfeiting some availability, or proceed with the operation, forfeiting some potential
consistency.

So, we've detected a partition by some detection of timeouts. What operations should be
allowed to proceed? The answer to this question depends on the invariants the system needs
to preserve, and thus fundamentally captures the tradeoff between consistency and
availability the system is making.

* You could make invariants locally-satisfiable (sharding). This allows more operations to
  proceed without forfeiting any consistency.
* You could proceed with operations that might break global invariants, but attempt to fix
  them after the partition is over.
* Recording intents to do certain operations after the partition _in general_ is common.

Partition recovery then boils down to examining the histories on both sides of the
partition and attempting to merge them into a single, valid history, fixing any errors,
and accounting for any outputs the system made during that time. Merging arbitrary
operations is an extremely difficult operation; but merging a constrained set of
operations can be easy or even trivial (commutative types).

Fixing errors is less easy, especially if the errors have been output. Kicking a
passenger off a flight is nontrivial, but occasionally doable.

So what this article tells me is that to properly analyse a system, I need to look at:

* how it detects a partition (and thus what kinds of partitions it might miss)
* what operations it allows under a detected partition (and thus what kinds of invariants can be violated)
* how it recovers once the partition has healed (and thus what kinds of consistency violations it can withstand)

Brewer also seems to completely ignore analysis of what the system does while not under a
partition. While it's true that a system can be theoretically fully CA at that point, I
know many real world systems aren't—surely this is a relevant axis of characterisation?
Whether it's theoretically interesting or not, I'm sure there are systems that make
practical choices rendering them unable of _ever_ offering full C or A.

That would be my next research step—searching for ways to analyse the tradeoffs a system
makes between consistency and availability even in the presence of no partitions.
