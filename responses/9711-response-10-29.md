This paper presents a framework for specifying what the authors call replicated data types (for some strange reason they don't call them CRDT's even though they mention the classic CRDT examples in the abstract of the paper) via relations between events and in a very PL fashion verifying the implementations. They do bring up a good point about eventual consistency being a vague buzzword. I somewhat wish that they would define quiescent consistency in more detail. The authors give an example of an anomaly in replicated data store. The authors then present their ideas for reasoning about replicated data stores in three areas specification, verification, and optimality. They present a framework for creating specifications of replicated data stores not with a function of states but with operation contexts (a set of events). The authors also present something that they call replication aware simulations which will consider the state of messages and replicas as two different entities and consider abstract descriptions of only the events causally preceding said state. Therefore they only have to reason about a single replica at a time while attempting to verify an implementation. Another challenge arises concerning how the code can modify messages and objects at the same time. This challenge is met with something the authors call agreement properties that relate messages to object state. Lastly the authors discuss the optimality of implementations. Specifically they attack the issue of worst case metadata overhead. Their optimization technique is applied to the same implementations as their specification and verification methods. The authors use operation and state based counters and a state based last writer wins register, along with an observe-remove set and a multi value register. Their specification technique relies on the concept of an abstract execution.

One thing I learned from this paper is a non-state based method for specifications of replicated data types. What I still do not quite understand from this paper is how exactly they are going about handling optimizations. Though that is likely because once I made it to that part of the paper I was rather tired.  My research question is actually related to my current blog post topic. While going through the “comprehensive” CRDT paper I have noticed that the authors omit certain, sometimes essential, operations due to difficulties in developing semantics for them. I am wondering if the semantic specification techniques presented in this paper would be of any help in resolving the shortcomings of the previous one. A concrete step towards answering this question would be expressing a CRDT (one of the ones with flaws) from the previous paper in the specification method described in this one.
